#!/usr/bin/env python
"""Get light curves of supernova candidates from DES database.

If no SNIDs are given, all candidates with numepochs_ml >= 2 in the SNCAND
table are retrieved. Otherwise, only candidates with the given SNIDs
are retrieved (regardless of whether they have been scanned).

By default, the light curves are retrieved from the SNFORCE table, with
a query on SNCAND_ID. This behavior can be changed using the --table
flag. For the SNOBS table, the query is based on RA and DEC (within a
box of radius 1.08 arcsec). Note that the 'status' fields in the
SNFORCE and SNOBS tables have different meanings.

For the SNFORCE table, when there are multiple rows with the same
EXPNUM (exposure number from the EXPOSURE table), the row with the
latest image_id (from the IMAGE table) is returned; others are
discarded. This assumes that the latest image_id is the 'best'.

SNPHOTMS table: This table is in the Y1LEGACY schema in the DESOPER
database.  To query this table, you must connect to the database with
credentials that have the Y1LEGACY schema. The '-u' and '-p' optional
arguments can be used to override the default username and
password. If you are querying for candidates (rather than requesting a
specific set of candidate IDs), use '--candtable=sncand_legacy'.
"""

import sys
import os
import glob
import math
from textwrap import dedent
from datetime import datetime
from optparse import OptionParser
import time
import json
try:
    from collections import OrderedDict as odict
except ImportError:
    odict = dict

import numpy as np
import cx_Oracle
import desdb
try:
    from desdb.desdb import PasswordGetter  # new location in desdb
except ImportError:
    from desdb import PasswordGetter  # old location in desdb

TABLES = ['snforce', 'snobs', 'snphotms']
FORMATS = ['ascii', 'json', 'fits']
SUFFIXES = {'ascii': 'dat', 'json': 'json'}  # Single LC formats
SNOBS_BOXRAD = 1.08 / 3600.  # in degrees

# Utility ================================================================== #
def dict_to_array(d, keys=None):
    """Convert a dict of arrays (of equal length) to a structured array."""

    if keys is None:
        keys = d.keys()

    size = len(d[keys[0]])
    dtype = [(key, d[key].dtype) for key in keys]
    result = np.empty(size, dtype=dtype)
    for key in keys:
        result[key] = d[key]

    return result

# Writers ================================================================== #
def write_single_ascii(fname, data, meta, **kwargs):
    """Write a single light curve to an ASCII file"""

    delim = kwargs.get('delim', ' ')
    metachar = kwargs.get('metachar', '@')
    keys = data.dtype.names
    length = len(data)

    with open(fname, 'wb') as f:
        if meta is not None:
            for key, val in meta.iteritems():
                f.write('{0}{1}{2}{3}\n'.format(metachar, key, delim, val))

        f.write(delim.join(keys))
        f.write('\n')
        for i in range(length):
            f.write(delim.join([str(data[key][i]) for key in keys]))
            f.write('\n')


def write_single_json(fname, data, meta):
    """Write a single light curve to a JSON-format file"""

    # Build a dictionary of pure-python objects
    output = odict([('meta', meta), ('data', odict())])
    for key in data.dtype.names:
        output['data'][key] = data[key].tolist()

    with open(fname, 'wb') as f:
        json.dump(output, f, encoding=sys.getdefaultencoding())


def write_multiple_fits(meta_list, data_list, fname, header=None):
    """Write multiple light curves to a two-extension FITS file.

    Parameters
    ----------
    meta_list : list of dict
        All with same keys. Length must match that of ``data_list``.
    data_list : list of numpy.ndarrays
        All with same dtype.
    fname : str
        Output filename.
    header : dict
        Global header (added as FITS keywords in first extension).
    """

    from fitsio import FITS

    if len(data_list) != len(meta_list):
        raise ValueError("length of data_list and meta_list must match")
    if len(data_list) == 0:
        raise ValueError("length of data_list is zero: can't write to FITS")


    # collect one giant array that will hold all of the data arrays.
    nrows = sum([len(d) for d in data_list])
    dtype = data_list[0].dtype
    alldata = np.empty(nrows, dtype)
    
    # Loop over data_list
    start = 0
    ind = 0
    while data_list:
        data = data_list.pop(0)  # remove first item
        end = start + len(data)
        alldata[start:end] = data
        meta_list[ind]['datastart'] = start
        meta_list[ind]['dataend'] = end
        start = end
        ind += 1

    meta_names = meta_list[0].keys()
    meta_arrays = [np.array([meta[n] for meta in meta_list])
                   for n in meta_names]
    allmeta = odict(zip(meta_names, meta_arrays))
    allmeta = dict_to_array(allmeta)

    f = FITS(fname,'rw')
    f.write(allmeta)
    f.write(alldata)
    f[0].write_keys(header)  # write global header
    f.close()


# Argument parser ========================================================== #
def parse_args():

    parser = OptionParser(usage='%prog [options] [SNID ...]',
                          description=__doc__)

    # Credentials
    parser.add_option("-u", "--user", default=None,
                      help="override username in .netrc")
    parser.add_option("-p", "--password", default=None,
                      help="override password in .netrc")

    # Which candidates?
    parser.add_option("-n", type="int", default=-1,
                      help="maximum number of light curves to get (default "
                      "behaviour is to get all matching light curves)")
    parser.add_option("--dbname", default='desoper',
                      help="Database to connnect to: desoper, destest "
                      "(default: desoper)") 
    parser.add_option("--candtable", default='sncand',
                      help="Table to query for candidates: sncand, "
                      "sncand_legacy (default: sncand)") 
    parser.add_option("--candtype", default=0,
                      help="Get only candidates with this cand_type value, "
                      "or 'all' to disregard cand_type (default: 0)")
    parser.add_option("--hasphot", default=False, action='store_true',
                      help='Check that candidates are in photometry table ' 
                      'before fetching light curves. Only return light curves '
                      'for candidates with photometry.')
    parser.add_option("--infile", default=None,
                      help="Read SNIDs from this file instead of arguments.")
    parser.add_option("--mindate", default=None,
                      help="minimum candidate entry_date, format: YYYY-MM-DD")
    parser.add_option("--maxdate", default=None,
                      help="maximum candidate entry_date, format: YYYY-MM-DD")

    # Which fake candidates?
    parser.add_option("--fake", default=False, action='store_true',
                      help="get light curves for fake candidates (candidates "
                      "with snfake_id > 0) instead of real ones")
    parser.add_option("--minfakeid", default=-1, type="int",
                      help="minimum fake_id (only effective with --fake flag)")
    parser.add_option("--maxfakeid", default=-1, type="int",
                      help="maximum fake_id (only effective with --fake flag)")

    # Content: which photometry table? optional metadata?
    parser.add_option("-t", "--table", default='snforce',
                      help=("table from which to retrieve photometry: "+
                            ",".join(TABLES) + " (default: snforce)"))
    parser.add_option("--galflux", default=False, action='store_true',
                      help="Include galflux in metadata (average of "
                      "SNOBS.GALFLUX column for nearby entries)")

    # Output formatting?
    parser.add_option("--format", default='ascii',
                      help=("file format for output: " + ",".join(FORMATS) +
                            " (default=ascii)"))
    parser.add_option("-b", "--bandnames", default='g,r,i,z',
                      help="comma-separated list of names of the DES "
                      "g, r, i, z bands, as they should appear in the "
                      "output files. example: 'desg,desr,desi,desz' default: "
                      "'g,r,i,z'")

    # Output location?
    parser.add_option("-o", "--output", default='.',
                      help="output directory (default='.')")
    parser.add_option("-c", "--clobber", default=False, action='store_true',
                      help="overwrite (refetch) existing files")

    # Verbosity?
    parser.add_option("-v", "--verbose", default=False, action='store_true',
                      help="print query string for all queries")

    opts, args = parser.parse_args(sys.argv[1:])

    if opts.infile is not None:
        with open(opts.infile, 'r') as f:
            snids = f.read().split()
    else:
        snids = args
    
    if opts.candtable not in ["sncand", "sncand_legacy"]:
        print "candtable must be one of: sncand, sncand_legacy"
        sys.exit(1)

    if opts.table not in TABLES:
        print "Table must be one of: " + ",".join(TABLES)
        sys.exit(1)

    opts.format = opts.format.lower()
    if opts.format == 'csv': opts.format = 'ascii'  # backwards compatibility
    if opts.format not in FORMATS:
        print "Format must be one of:", ', '.join(FORMATS)
        sys.exit(1)

    # Check output, depending on format
    if opts.format == 'fits':
        import fitsio   # fail immediately if fitsio not installed
        if not opts.output.endswith(".fits"):
            raise Exception("For fits format, output must have .fits suffix.")
        if os.path.exists(opts.output):
            raise Exception("Target output %s already exists" % opts.output)
    else:
        if not os.path.exists(opts.output):
            print "--output: must specify an existing directory"
            sys.exit(1)
        opts.output = opts.output.rstrip('/')

    # Turn bandnames into a lookup table
    names = opts.bandnames.split(',')
    if len(names) != 4:
        print "bandnames must have 4 comma-separated elements"
        sys.exit(1)
    opts.bandnames = {'g': names[0],'r': names[1],'i': names[2],'z': names[3]}

    return snids, opts


# Query string builders ==================================================== #
def build_cand_query(snids, opts):

    # Query for real candidates:
    if not opts.fake:
        q = dedent(
            """
            SELECT
                c.snid, c.transient_id, c.transient_name, c.ra, c.dec,
                c.cand_type, c.cand_desc, c.numepochs,
                c.numobs, c.numepochs_ml, c.num_artifact, c.num_unsure,
                c.num_unscanned, c.entry_date, c.snfake_id as fake_id
            FROM
                {0} c
            WHERE
                c.snfake_id=0
            """.format(opts.candtable))
        if len(snids) == 0 and not opts.candtable == 'sncand_legacy':
            q += "    AND c.numepochs_ml >= 2\n"

    # Query for fake candidates:
    else:
        q = dedent(
            """
            SELECT
                c.snid, c.transient_id, c.transient_name, c.ra, c.dec,
                c.cand_type, c.cand_desc, c.numepochs,
                c.numobs, c.numepochs_ml, c.num_artifact, c.num_unsure,
                c.num_unscanned, c.entry_date, c.snfake_id as fake_id,
                f.galid as fake_galid, f.z as fake_z,
                f.peakmjd as fake_peakmjd, f.host_angsep as fake_hostsep,
                f.hostmag_i as fake_hostmag_i
            FROM
                {0} c, snfake f
            WHERE
                c.snfake_id>0
                AND c.snfake_id=f.id
            """.format(opts.candtable))
        if opts.minfakeid >= 0:
            q += "    AND c.snfake_id >= {0:d}".format(opts.minfakeid)
        if opts.maxfakeid >= 0:
            q += "    AND c.snfake_id <= {0:d}".format(opts.maxfakeid)

    if opts.hasphot:
        # only fetch the rows that have photometry
        q += "    AND c.snid IN (SELECT DISTINCT SNCAND_ID FROM %s)\n" % opts.table

    # Get just certain candidates?
    if len(snids) > 0:
        # divide ints from non-ints
        intsnids = []
        strsnids = []
        for snid in snids:
            try:
                intsnids.append(int(snid))
            except ValueError:
                strsnids.append(snid)
        intsnids = ", ".join([str(snid) for snid in intsnids])
        strsnids = ", ".join([repr(snid) for snid in strsnids])
        
        if intsnids and strsnids:
            q += ("    AND ((c.snid in ({0})) OR\n"
                  "         (c.transient_name in ({1})))\n"
                  .format(intsnids, strsnids))
        elif intsnids:
            q += "    AND c.snid in ({0})\n".format(intsnids)
        elif strsnids:
            q +=  "    AND c.transient_name in ({0})\n".format(strsnids)

    # specify cand_type=0 if we didn't request specific candidates:
    if len(snids) == 0 and opts.candtype != 'all':
        q += "    AND c.cand_type={0:d}\n".format(int(opts.candtype))

    # Any specific dates?
    if opts.mindate is not None:
        q += "    AND c.entry_date >= date '{0}'\n".format(opts.mindate)
    if opts.maxdate is not None:
        q += "    AND c.entry_date <= date '{0}'\n".format(opts.maxdate)

    # Maximum number of candidates to retrieve?
    if opts.n >= 0:
        q += "    AND rownum <= {0:d}\n".format(opts.n)

    q += "ORDER BY c.snid"
    return q


def build_snforce_query(snid, fake_id):

    q = """
        SELECT
            field, ccdnum, band, mjd_obs, flux, flux_err, status, expnum
        FROM
            snforce
        WHERE
            sncand_id = {0:d}
        ORDER BY
            expnum
        """.format(snid)

    # Get more information from the snobsinfo and snquality
    # tables.  This has to be implemented as a sub-query
    # because we need to `left outer join` to the snobsinfo
    # table based on *both* expnum and ccdnum and these values
    # come from two different tables.
    fullq_template = """
        SELECT
            ph.*,
            oi.psf_nea,
            oi.chip_sigsky,
            oi.chip_zero_point,
            oi.chip_zero_point_rms,
            nvl(q.snqual, 0) as snqual{0}
        FROM
            ({1}) ph
            LEFT OUTER JOIN snobsinfo oi
                ON oi.expnum = ph.expnum
                AND oi.tile = 0
                AND oi.ccdnum = ph.ccdnum
                AND oi.band = ph.band
            LEFT OUTER JOIN snquality q
                ON ph.expnum = q.expnum{2}
        ORDER BY
            ph.expnum
        """

    # If we're doing fakes, tack on some more info from FAKEIMG
    addfields = ""
    addjoin = ""
    if fake_id != 0:
        addfields = ", fi.truemag as fake_truemag"
        addjoin = """
            LEFT OUTER JOIN snfakeimg fi
                ON fi.expnum = ph.expnum
                AND fi.snfake_id = {0:d}""".format(fake_id)

    return fullq_template.format(addfields, q, addjoin)

def build_snphotms_query(snid, fake_id):

    q = """
        SELECT
            field, ccdnum, band, mjd_obs, flux, flux_err, expnum, zp
        FROM
            snphotms
        WHERE
            sncand_id = {0:d} AND exp_type='data'
        ORDER BY
            expnum
        """.format(snid)

    # Get more information from the snobsinfo and snquality
    # tables.  This has to be implemented as a sub-query
    # because we need to `left outer join` to the snobsinfo
    # table based on *both* expnum and ccdnum and these values
    # come from two different tables.
    fullq_template = """
        SELECT
            ph.*,
            oi.psf_nea,
            oi.chip_sigsky,
            oi.chip_zero_point,
            oi.chip_zero_point_rms,
            nvl(q.snqual, 0) as snqual{0}
        FROM
            ({1}) ph
            LEFT OUTER JOIN snobsinfo oi
                ON oi.expnum = ph.expnum
                AND oi.tile = 0
                AND oi.ccdnum = ph.ccdnum
                AND oi.band = ph.band
            LEFT OUTER JOIN snquality q
                ON ph.expnum = q.expnum{2}
        ORDER BY
            ph.expnum
        """

    # If we're doing fakes, tack on some more info from FAKEIMG
    addfields = ""
    addjoin = ""
    if fake_id != 0:
        addfields = ", fi.truemag as fake_truemag"
        addjoin = """
            LEFT OUTER JOIN snfakeimg fi
                ON fi.expnum = ph.expnum
                AND fi.snfake_id = {0:d}""".format(fake_id)

    return fullq_template.format(addfields, q, addjoin)


def build_snobs_query(ra, dec):

    dra = SNOBS_BOXRAD * math.cos(dec * math.pi/180.)
    ddec = SNOBS_BOXRAD
    q = """
    SELECT
        substr(e.object, 22, 2) field, e.band, e.mjd_obs,
        o.flux, o.flux_err, o.mag, o.status, e.expnum
    FROM
        exposure e, snobs o
    WHERE
        o.ra between {0:f} and {1:f}
        AND o.dec between {2:f} and {3:f}
        AND o.exposureid=e.expnum
    ORDER BY
        e.expnum
    """.format(ra - dra, ra + dra, dec - ddec, dec + ddec)
    return q

def build_galflux_query(ra, dec):
    """Similar to above query, but just get average galflux for all
    entries within the SNOBS_BOXRAD"""

    dra = SNOBS_BOXRAD * math.cos(dec * math.pi/180.)
    ddec = SNOBS_BOXRAD
    q = """
    SELECT
        band, avg(galflux) as galflux
    FROM
        snobs
    WHERE
        ra between {0:f} and {1:f}
        AND dec between {2:f} and {3:f}
        AND band in ('g','r','i','z')  /* eliminate entries with band = 'N' */
    GROUP BY
        band
    """.format(ra - dra, ra + dra, dec - ddec, dec + ddec)
    return q


def build_sngals_query(snid):
    q = """
    SELECT
        g.photoz as host_photoz, g.photoz_err as host_photoz_err,
        g.specz as host_specz, g.specz_err as host_specz_err,
        g.specz_catalog as host_specz_catalog,
        g.separation as host_separation, g.dlr as host_dlr,
        g.mag_aper_4_g as host_mag_aper_4_g,
        g.mag_aper_4_r as host_mag_aper_4_r,
        g.mag_aper_4_i as host_mag_aper_4_i,
        g.mag_aper_4_z as host_mag_aper_4_z,
        g.magerr_aper_4_g as host_magerr_aper_4_g,
        g.magerr_aper_4_r as host_magerr_aper_4_r,
        g.magerr_aper_4_i as host_magerr_aper_4_i,
        g.magerr_aper_4_z as host_magerr_aper_4_z
    FROM
        sngals g
    WHERE
        g.snid = {0:d}
        AND (g.host = 1 OR g.dlr_rank = -1)
    """.format(snid)
    return q

# Main ===================================================================== #
if __name__ == "__main__":

    # Parse command-line args
    snids, opts = parse_args()

    # Get start time & database username.
    t0 = time.time()
    user = PasswordGetter().user

    # Create a connection to the database.
    conn = desdb.connect(dbname=opts.dbname,
                         user=opts.user,
                         password=opts.password)

    # Build and run candidate query
    q = build_cand_query(snids, opts)
    if opts.verbose:
        print 78 * '=', '\n', "candidate query:\n", 78 * '=', '\n', q, '\n'
    cands = conn.quick(q)
    
    # specify order of keys in photometry tables
    photkeys = ['time', 'field', 'band', 'flux', 'fluxerr', 'zp', 'zpsys',
                'status', 'expnum']
    if opts.table in ('snforce', 'snphotms'):
        photkeys.extend(['ccdnum', 'psf_nea', 'chip_sigsky',
                         'chip_zero_point', 'chip_zero_point_rms', 'snqual'])
        if opts.fake:
            photkeys.append('fake_truemag')

    if opts.table == 'snphotms':
        photkeys.remove('status')

    # FITS format: initialize containers to hold candidate data as we go.
    if opts.format == 'fits':
        meta_list = []
        data_list = []
        primaryheader = odict(
            [('dbuser', user),
             ('qrytime', datetime.now().strftime('%Y-%m-%dT%H:%M:%S')),
             ('qryutc', datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')),
             ('dbtable', opts.table)])

    # Loop over candidates
    print '',
    ncands = len(cands)
    nempty = 0
    for i, cand in enumerate(cands):

        # For single light curve formats, check if file already exists.
        if opts.format in SUFFIXES:
            fname = '{0}/des{1:08d}.{2}'.format(opts.output, cand['snid'],
                                                SUFFIXES[opts.format])
            if not opts.clobber and os.path.exists(fname):
                continue

        # Info line.
        print '\rsnid ={0:8d} ({1:6d}/{2:6d})'.format(cand['snid'],i+1,ncands),
        sys.stdout.flush()

        # Build the query string and run it
        if opts.table == 'snforce':
            q = build_snforce_query(cand['snid'], cand['fake_id'])
        elif opts.table == 'snobs':
            q = build_snobs_query(cand['ra'], cand['dec'])
        elif opts.table == 'snphotms':
            q = build_snphotms_query(cand['snid'], cand['fake_id'])
        if opts.verbose:
            print '\n', 78 * '-', '\n', dedent(q)
        data = conn.quick(q, array=True)

        # Check if data is empty
        if len(data) == 0:
            nempty += 1
            continue
            
        # HACKS ----------------------------------------------------------
        # Get just the latest image ID for each exposure (expnum)
        # This counts on the data being ordered by (expnum, image_id).
        
        # UPDATE: There should be no duplicates now (ha!)

        # if opts.table == 'snforce':
        #    indicies_to_use = []
        #    for i in range(1, len(data)):
        #        if not (data['expnum'][i] == data['expnum'][i-1]):
        #            indicies_to_use.append(i-1)
        #    indicies_to_use.append(len(data)-1)
        #    data = data[indicies_to_use]

            # Sometimes forced photometry was mistakenly run on
            # diff_single_diff imagetypes when a diff_nitecmb_diff
            # image was available. This was fixed in Fall 2013 (at
            # some point)
            #
            # TODO: remove this hack once snforce table is
            #       cleaned in off- season.  Mask rows where imagetype =
            #       'diff_single_diff' that are from deep fields or z band.

            # UPDATE: I think its ok to remove this now (9/5/2014)

            #mask = (
            #    (data['imagetype'] == 'diff_single_diff') &
            #    (np.char.endswith(data['field'], '3') | (data['band'] == 'z'))
            #    )
            #data = data[~mask]
        # END HACKS -----------------------------------------------------

        # Convert `data` to a dictionary of arrays so we can manipulate
        # some of the columns.
        nrows = len(data)
        data = {key: data[key] for key in data.dtype.names}

        # Convert band names
        data['band'] = np.array([opts.bandnames[b.strip()]
                                 for b in data['band']])

        # Add zeropoint information
        if opts.table == 'snforce':
            data['zp'] = 31.4 * np.ones(nrows)
        elif opts.table == 'snobs':
            data['zp'] = data['mag'] + 2.5 * np.log10(data['flux'])
            del data['mag']
        data['zpsys'] = np.array(nrows * ['ab']) 

        # Rename some columns
        data['time'] = data.pop('mjd_obs')
        data['fluxerr'] = data.pop('flux_err')

        # Convert to a structured numpy array
        data = dict_to_array(data, keys=photkeys)

        # Create metadata.
        meta = odict()
        if opts.format != 'fits':
            meta['query_user'] = user
            meta['query_time'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
            meta['query_utc'] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')
            meta['query_table'] = opts.table
        meta.update(cand)

        # Convert entry_date from datetime object to a string.
        meta['entry_date'] = meta['entry_date'].strftime('%Y-%m-%dT%H:%M:%S')

        # Initialize host info in metadata.
        meta.update({'host_photoz': None, 'host_photoz_err': None,
                    'host_specz': None, 'host_specz_err': None,
                    'host_specz_catalog': None, 'host_separation': None,
                    'host_dlr': None,
                    'host_mag_aper_4_g': None, 'host_mag_aper_4_r': None,
                    'host_mag_aper_4_i': None, 'host_mag_aper_4_z': None,
                    'host_magerr_aper_4_g': None, 'host_magerr_aper_4_r': None,
                    'host_magerr_aper_4_i': None, 'host_magerr_aper_4_z': None})

        # Get host galaxy info from the SNGALS table.
        q = build_sngals_query(cand['snid'])
        if opts.verbose:
            print dedent(q)
        gals = conn.quick(q)
        if len(gals) == 1:
            meta.update(gals[0])
        # No cases where host=1 AND dlr_rank=-1 by construction
        elif len(gals) > 1:
            raise RuntimeError('More than one matching SNGALS entry with '
                               'HOST=1 for SNID=' + str(cand['snid']))

        # If requested, get average galflux from SNOBS table.
        if opts.galflux:
            meta.update({'galflux_g': None, 'galflux_r': None,
                         'galflux_i': None, 'galflux_z': None})
            q = build_galflux_query(cand['ra'], cand['dec'])
            if opts.verbose:
                print dedent(q)
            res = conn.quick(q)
            meta.update({'galflux_' + row['band']: row['galflux']
                         for row in res})

        # HACK ----------------------------------------------------------
        # `None` in num* columns means `0`.
        for key in meta:
            if key.startswith('num') and meta[key] is None:
                meta[key] = 0
        # ---------------------------------------------------------------

        if opts.format == 'ascii':
            for key in meta:  # Convert missing values to 'NULL'
                if meta[key] is None: meta[key] = 'NULL'
            write_single_ascii(fname, data, meta)

        elif opts.format == 'json':
            write_single_json(fname, data, meta)

        elif opts.format == 'fits':
            # Convert missing values to something writable.
            for key in meta:
                if meta[key] is None:
                    if key == 'host_specz_catalog':
                        meta[key] = ''
                    else:
                        meta[key] = np.nan
            meta_list.append(meta)
            data_list.append(data) 

    # for FITS format, write it all out.
    if opts.format == 'fits':
        if len(data_list) == 0:
            print "0 candidates with photometric data; FITS file not written."
        else:
            write_multiple_fits(meta_list, data_list, opts.output,
                                header=primaryheader)

    elapsed = time.time() - t0
    print "\n{0:d} snids missing photometry were skipped".format(nempty)
    print "Total time: {0:d}m{1:05.2f}s".format(int(elapsed)/60, elapsed%60)
